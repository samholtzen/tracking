{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0fd60-3c2f-4873-8e90-b26e3fdd116f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '16'\n",
    "os.environ['MKL_NUM_THREADS'] = '16'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '16'\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '16'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "import imageio\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)\n",
    "\n",
    "import wellmap\n",
    "\n",
    "sys.path.append('utils/')\n",
    "import live_utils\n",
    "\n",
    "from deepcell.applications import NuclearSegmentation, CellTracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warm up segmentation and tracking models\n",
    "app = NuclearSegmentation.from_version(\"1.1\")\n",
    "tracker = CellTracking.from_version(\"1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc94e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_date = 'example'\n",
    "\n",
    "metadata = wellmap.load(f'data/wellmap/{experiment_date}.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf85666-50fa-440b-b935-0bdeac0e895b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for _, row in tqdm(metadata.iterrows()):\n",
    "\n",
    "    nuc_area = row['nuc_area']\n",
    "    dilation_size = row['dilation_size']\n",
    "\n",
    "    image_directory = row['path_to_live']\n",
    "    output_directory = row['output_dir']\n",
    "    dirname = output_directory+'/processed'\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "    nuc_channel = row['live_nuc_channel']\n",
    "    channel_to_register = row['registration_channel']\n",
    "    registration_type = row['registration_type']\n",
    "\n",
    "    file = glob.glob(f\"{row['path_to_live']}/Well{row['well0']}*.nd2\")[0]\n",
    "\n",
    "    if not os.path.isdir(image_directory):\n",
    "        raise FileNotFoundError(\"That image directory doesn't exist. Try again.\")\n",
    "    \n",
    "    if not os.path.isfile(file):\n",
    "        raise FileNotFoundError(\"That image file doesn't exist. Try again.\")\n",
    "    \n",
    "    if nuc_channel is None:\n",
    "        raise ValueError(\"Please indicate the nuclear channel.\")\n",
    "\n",
    "    if nuc_area is None:\n",
    "        raise ValueError(\"Please indicate the nuclear area to filter out.\")\n",
    "\n",
    "    if channel_to_register is None:\n",
    "        raise ValueError(\"Please indicate the channel you would like to use for registration.\")\n",
    "\n",
    "    if not os.path.exists(f'{output_directory}/{os.path.basename(file)}'):\n",
    "        shutil.copy2(file, f'{output_directory}/{os.path.basename(file)}')\n",
    "\n",
    "    file = f'{output_directory}/{os.path.basename(file)}'\n",
    "    \n",
    "    # Get input and output names for writing the files\n",
    "    filename = live_utils.get_outdirs(file)\n",
    "    \n",
    "    # Get microns per pixel and image sizes from metadata\n",
    "    mpp, image_sizes = live_utils.get_mpp_from_nd2(file)        \n",
    "    \n",
    "    # Make numpy array of the image and move channel axis to the end\n",
    "    full_image = live_utils.get_npy(file, row)\n",
    "\n",
    "    registered_image =  live_utils.register_image_stack(full_image)\n",
    "\n",
    "    if os.path.exists(f'{output_directory}/{filename}_nuc_mask.npy'):\n",
    "        \n",
    "        registered_mask = np.load(f'{output_directory}/{filename}_nuc_mask.npy')\n",
    "        \n",
    "    else:\n",
    "        # Make and clean the nuclear mask\n",
    "        registered_mask = live_utils.segment_and_clean(registered_image, mpp, nuc_area=nuc_area, nuc_channel=nuc_channel, segment_app=app)\n",
    "\n",
    "    if row['save_mask']:\n",
    "        np.save(f'{output_directory}/{filename}_nuc_mask.npy', registered_mask)\n",
    "\n",
    "    # Register the image and mask stacks\n",
    "    \n",
    "    live_utils.track_and_pickle(registered_image, registered_mask, nuc_channel=nuc_channel, tracker=tracker, dirname=dirname, filename=filename, dilation_size=dilation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38bec7",
   "metadata": {},
   "source": [
    "Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838aaf99-1d72-4806-9e81-e73218585bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06643d023ad54ceaa96b83967313fe45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def adjust_contrast_limits(image, vmin=None, vmax=None):\n",
    "    \"\"\"\n",
    "    Adjust the contrast limits of an image using linear scaling.\n",
    "    \"\"\"\n",
    "    if vmin is None:\n",
    "        vmin = np.percentile(image, 2)  # Default to the 2nd percentile as lower limit\n",
    "    if vmax is None:\n",
    "        vmax = np.percentile(image, 99.99)  # Default to the 98th percentile as upper limit\n",
    "    # Perform linear scaling\n",
    "    return np.clip((image - vmin) / (vmax - vmin), 0.1, 1)\n",
    "\n",
    "def plot(x, y, cmap=None, vmax=None):\n",
    "    yy = copy.deepcopy(y)\n",
    "    xx = copy.deepcopy(x)\n",
    "\n",
    "    yy = np.ma.masked_equal(yy, 0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(xx, cmap='gray', vmax=5000)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Raw')\n",
    "    ax[1].imshow(yy, cmap=cmap, vmax=vmax)\n",
    "    ax[1].set_title('Tracked')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.buffer_rgba(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "folder_to_open = metadata['output_dir']+'/processed'\n",
    "pickles_to_open = glob.glob(f'{folder_to_open}/*.pickle')\n",
    "\n",
    "for idx, row in tqdm(metadata.iterrows()):\n",
    "\n",
    "    folder_to_open = row['output_dir']+'/processed'\n",
    "    well = row['well0']\n",
    "    pickles_to_open = glob.glob(f'{folder_to_open}/Well{well}*.pickle')[0]\n",
    "    pickle_name = os.path.splitext(os.path.basename(pickles_to_open))[0]\n",
    "    \n",
    "    with open(pickles_to_open, 'rb') as file:\n",
    "        tracks = pickle.load(file)\n",
    "    \n",
    "    y_tracked = tracks['y_tracked']\n",
    "    x = tracks['registered_image']\n",
    "    ymax = np.max(y_tracked)\n",
    "    cmap = live_utils.shuffle_colors(ymax, 'tab20')\n",
    "    \n",
    "    imageio.mimsave(\n",
    "        \n",
    "        f'{pickle_name}.gif',\n",
    "        \n",
    "        [plot(np.sum(x[i], axis=-1), y_tracked[i,...,0], cmap=cmap, vmax=ymax)\n",
    "         \n",
    "         for i in range(y_tracked.shape[0])]\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0957e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "\n",
    "dirname = output_directory+'/processed'\n",
    "\n",
    "pickle_open = glob.glob('/data/sholtzen/barcode_dynamics/20250528/processed/Well*.pickle')\n",
    "\n",
    "for pickle_name in tqdm(pickle_open):\n",
    "    alphanum = os.path.basename(pickle_name).split('_')[0].strip('Well')\n",
    "\n",
    "\n",
    "    with open(pickle_name, 'rb') as file:\n",
    "        tracks = pickle.load(file)\n",
    "\n",
    "    n_frames = tracks['y_tracked'].shape[0]\n",
    "    n_channels = tracks['registered_image'].shape[-1]\n",
    "    track_dict = tracks['tracks']\n",
    "\n",
    "    for i, track in enumerate(track_dict):\n",
    "        track_dict[i+1]['nuc_intensity'] = np.full((n_channels, n_frames), np.nan)\n",
    "        track_dict[i+1]['cyto_intensity'] = np.full((n_channels, n_frames), np.nan)\n",
    "        track_dict[i+1]['cell_intensity'] = np.full((n_channels, n_frames), np.nan)\n",
    "        track_dict[i+1]['exclude'] = False\n",
    "\n",
    "    for i in range(n_frames):\n",
    "\n",
    "        cytoring = tracks['cyto_mask'][i].squeeze()\n",
    "        nuc_mask = tracks['y_tracked'][i].squeeze()\n",
    "        curr_frame = tracks['registered_image'][i].copy()\n",
    "\n",
    "        cyto_props = regionprops(cytoring, curr_frame)\n",
    "        nuc_props = regionprops(nuc_mask, curr_frame)\n",
    "        cell_props = regionprops(nuc_mask+cytoring, curr_frame)\n",
    "\n",
    "        for nuc_idx in range(len(nuc_props)):\n",
    "\n",
    "            cyto_label = cyto_props[nuc_idx].label\n",
    "            nuc_label = nuc_props[nuc_idx].label\n",
    "\n",
    "            track_dict[cyto_label]['cyto_intensity'][:,i] = cyto_props[nuc_idx].intensity_mean\n",
    "            track_dict[nuc_label]['nuc_intensity'][:,i] = nuc_props[nuc_idx].intensity_mean\n",
    "            track_dict[nuc_label]['cell_intensity'][:,i] = cell_props[nuc_idx].intensity_mean\n",
    "\n",
    "    tracks_list = tuple(track_dict.keys())\n",
    "\n",
    "    for track_idx in tracks_list:\n",
    "        track_len = len(track_dict[track_idx]['frames'])\n",
    "\n",
    "        # Has to exist for the whole movie\n",
    "        if track_len < n_frames:\n",
    "            track_dict.pop(track_idx)\n",
    "        \n",
    "    \n",
    "    track_dict = live_utils.gmm_filter_tracks(track_dict, n_channels=n_channels)\n",
    "    pickle_out = f'{dirname}/{alphanum}_tracks.pickle'\n",
    "    \n",
    "    with open(pickle_out, 'wb') as file:\n",
    "        pickle.dump(track_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = output_directory+'/processed'\n",
    "treatment_frame = metadata.loc[0,'treatment_frame']\n",
    "n_channels = 4\n",
    "\n",
    "fp_ylims = (1, 1, 1)\n",
    "\n",
    "for i, row in metadata.iterrows():\n",
    "\n",
    "    pickle_name = f\"/{row['output_dir']}/processed/{row['well0']}_tracks.pickle\"\n",
    "\n",
    "    alphanum = row['well0']\n",
    "\n",
    "    print(row['treatment'])\n",
    "\n",
    "    with open(pickle_name, 'rb') as file:\n",
    "        track_dict = pickle.load(file)\n",
    "\n",
    "    fig, ax = plt.subplots(1, n_channels-1, figsize=(8,2))\n",
    "\n",
    "    for channel in range(n_channels-1):\n",
    "\n",
    "        channel_store = []\n",
    "\n",
    "        for track_idx in tuple(track_dict.keys()):\n",
    "\n",
    "            if ~(track_dict[track_idx]['exclude']) & (track_dict[track_idx]['channel_exclude'][channel]):\n",
    "                    \n",
    "                    cn_ratio = track_dict[track_idx]['cyto_intensity'][channel,:]/track_dict[track_idx]['nuc_intensity'][channel,:]\n",
    "                    channel_store.append(cn_ratio)\n",
    "\n",
    "        channel_store = np.array(channel_store).transpose()\n",
    "\n",
    "        ax[channel].set_ylim((-0.2, fp_ylims[channel]))\n",
    "        \n",
    "        n_frames = channel_store.shape[0]\n",
    "        frame_vec = np.arange(n_frames)/10\n",
    "        mean_store = np.mean(channel_store, axis=1)\n",
    "        ax[channel].plot(frame_vec,mean_store - np.mean(mean_store[:treatment_frame]), linewidth=0.5, c='k')\n",
    "        ax[channel].set_xlabel('Time (h)')\n",
    "        ax[channel].set_title(row['live_channels'][channel])\n",
    "        ax[0].set_ylabel('C/N')\n",
    "\n",
    "    sensor = row['sensor']\n",
    "    treatment = row['treatment']\n",
    "    plt.savefig(f'{output_directory}/processed/{alphanum}_{sensor}_{treatment}')\n",
    "    plt.show()\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ef9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
